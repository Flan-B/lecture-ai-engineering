import os
import mlflow
import mlflow.sklearn
import pandas as pd
import numpy as np
import random
import pickle
import time
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from mlflow.models.signature import infer_signature



def prepare_data(test_size=0.2, random_state=42):
    path = "data/Titanic.csv"
    data = pd.read_csv(path)

    # å‰å‡¦ç†
    data = data[["Pclass", "Sex", "Age", "Fare", "Survived"]].dropna()
    data["Sex"] = LabelEncoder().fit_transform(data["Sex"])
    for col in ["Pclass", "Sex", "Age", "Fare", "Survived"]:
        data[col] = data[col].astype(float)

    X = data[["Pclass", "Sex", "Age", "Fare"]]
    y = data["Survived"]
    return train_test_split(X, y, test_size=test_size, random_state=random_state)



def train_and_evaluate(X_train, X_test, y_train, y_test, n_estimators=100, max_depth=None, random_state=42):
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)
    model.fit(X_train, y_train)
    accuracy = accuracy_score(y_test, model.predict(X_test))
    return model, accuracy


def log_model(model, accuracy, params, X_train, X_test):
    with mlflow.start_run():
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ã‚¹ã‚³ã‚¢
        for param_name, param_value in params.items():
            mlflow.log_param(param_name, param_value)
        mlflow.log_metric("accuracy", accuracy)

        # æ¨è«–æ™‚é–“
        start = time.time()
        _ = model.predict(X_test)
        elapsed = time.time() - start
        mlflow.log_metric("inference_time", elapsed)
        print(f"Inference time: {elapsed:.4f} seconds")

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        signature = infer_signature(X_train, model.predict(X_train))
        mlflow.sklearn.log_model(
            model,
            artifact_path="model",
            signature=signature,
            input_example=X_test.iloc[:5]
        )
        print(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ã‚°è¨˜éŒ²å€¤\naccuracy: {accuracy}\nparams: {params}")

    # ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜
    model_dir = "models"
    os.makedirs(model_dir, exist_ok=True)
    with open(os.path.join(model_dir, "titanic_model.pkl"), "wb") as f:
        pickle.dump(model, f)
    print("ğŸ“¦ ãƒ¢ãƒ‡ãƒ«ã‚’ models/titanic_model.pkl ã«ä¿å­˜ã—ã¾ã—ãŸ")



if __name__ == "__main__":
    # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    test_size = round(random.uniform(0.1, 0.3), 2)
    data_random_state = random.randint(1, 100)
    model_random_state = random.randint(1, 100)
    n_estimators = random.randint(50, 200)
    max_depth = random.choice([None, 3, 5, 10, 15])

    params = {
        "test_size": test_size,
        "data_random_state": data_random_state,
        "model_random_state": model_random_state,
        "n_estimators": n_estimators,
        "max_depth": "None" if max_depth is None else max_depth,
    }

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨å­¦ç¿’ãƒ»è©•ä¾¡
    X_train, X_test, y_train, y_test = prepare_data(test_size, data_random_state)
    model, accuracy = train_and_evaluate(X_train, X_test, y_train, y_test,
                                         n_estimators, max_depth, model_random_state)

    # ãƒ¢ãƒ‡ãƒ«ãƒ­ã‚°ï¼‹ä¿å­˜
    log_model(model, accuracy, params, X_train, X_test)
